{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6241ff97",
   "metadata": {
    "papermill": {
     "duration": 0.010495,
     "end_time": "2024-01-19T04:03:10.099218",
     "exception": false,
     "start_time": "2024-01-19T04:03:10.088723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìãTable of Contents\n",
    "* [INtroduction](#1)\n",
    "* [üìö Import Libraries](#2)\n",
    "* [üìñ Read Dataset](#3)\n",
    "* [üòÖüòÖMissing & Duplicate Values](#4) \n",
    "    - [Missing Values](#4.4)\n",
    "    - [Duplicates](#4.5)\n",
    "* [üñáüñáüì≠Data Pipeline](#7)\n",
    "    - [Creating X and y](#7.1)\n",
    "    - [Okay I need to explain](#7.2)\n",
    "    - [Main Pipeline](#7.3)\n",
    "* [‚öôÔ∏èFinding and Training Models With Best Hyperparameters](#8)\n",
    "    - [Random Jungle](#8.1)\n",
    "    - [My Cat](#8.2)\n",
    "    - [LGBM LIGHT](#8.3)\n",
    "    - [Extreme Guy](#8.4)\n",
    "* [üëÄüëÅFInal MOdel WIth VOting](#9)\n",
    "* [üìäGenerate Predictions and Create Submission File](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab132f78",
   "metadata": {
    "papermill": {
     "duration": 0.009465,
     "end_time": "2024-01-19T04:03:10.118551",
     "exception": false,
     "start_time": "2024-01-19T04:03:10.109086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center><a id = 1>INtroduction\n",
    "Hi , you clicked this notebook, so without any wasting time, let's get started..., Assuming (may be true or not) you're a beginner who needs a nice notebook to experiment with this  by forking it (so don't forget to upvote this)...\n",
    "   \n",
    "But some context.....\n",
    "![https://miro.medium.com/v2/resize:fit:1400/1*WqId29D5dN_8DhiYQcHa2w.png](https://miro.medium.com/v2/resize:fit:1400/1*WqId29D5dN_8DhiYQcHa2w.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0a3d4",
   "metadata": {
    "papermill": {
     "duration": 0.009428,
     "end_time": "2024-01-19T04:03:10.138269",
     "exception": false,
     "start_time": "2024-01-19T04:03:10.128841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why do customers churn?\n",
    "Here are four common reasons customers can churn:\n",
    "\n",
    "1. Price: by far, one of the most common reasons customers churn is price. Asking customers to pay top dollar for a product ‚Äì especially if they aren‚Äôt experiencing the value to make it worth it ‚Äì can be a stretch and quickly wear thin with decision-makers.\n",
    "\n",
    "2. Product: many times, customers purchase a product based on what it can do (or may be able to do in the future) to make their lives easier. If this product isn‚Äôt living up to expectations, or if promised features aren‚Äôt being delivered, the customer will churn.\n",
    "\n",
    "3. Competition: if you‚Äôre a SaaS organization, there will always be someone out there delivering the same thing to customers like you. If the competition becomes too appealing, there is often little you can do to pull a customer back in.\n",
    "\n",
    "4. State of business: sometimes, factors at play internally make it impossible for a customer to continue their vendor relationships. However, this reason cuts just as deep as some of the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36de379",
   "metadata": {
    "papermill": {
     "duration": 0.009477,
     "end_time": "2024-01-19T04:03:10.157522",
     "exception": false,
     "start_time": "2024-01-19T04:03:10.148045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The bank customer churn dataset is a commonly used dataset for predicting customer churn in the banking industry. It contains information on bank customers who either left the bank or continue to be a customer. The dataset includes the following attributes:**\n",
    "\n",
    "1. Customer ID: A unique identifier for each customer\n",
    "2. Surname: The customer's surname or last name\n",
    "3. Credit Score: A numerical value representing the customer's credit score\n",
    "4. Geography: The country where the customer resides (France, Spain or Germany)\n",
    "5. Gender: The customer's gender (Male or Female)\n",
    "6. Age: The customer's age.\n",
    "7. Tenure: The number of years the customer has been with the bank\n",
    "8. Balance: The customer's account balance\n",
    "9. NumOfProducts: The number of bank products the customer uses (e.g., savings account, credit card)\n",
    "10. HasCrCard: Whether the customer has a credit card (1 = yes, 0 = no)\n",
    "11. IsActiveMember: Whether the customer is an active member (1 = yes, 0 = no)\n",
    "12. EstimatedSalary: The estimated salary of the customer\n",
    "13. Exited: Whether the customer has churned (1 = yes, 0 = no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bb10f",
   "metadata": {
    "papermill": {
     "duration": 0.009804,
     "end_time": "2024-01-19T04:03:10.176860",
     "exception": false,
     "start_time": "2024-01-19T04:03:10.167056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> <a id = 2>üìöImport Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e6ab7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:10.199020Z",
     "iopub.status.busy": "2024-01-19T04:03:10.197934Z",
     "iopub.status.idle": "2024-01-19T04:03:15.196295Z",
     "shell.execute_reply": "2024-01-19T04:03:15.195118Z"
    },
    "papermill": {
     "duration": 5.012166,
     "end_time": "2024-01-19T04:03:15.198630",
     "exception": false,
     "start_time": "2024-01-19T04:03:10.186464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19751108",
   "metadata": {
    "papermill": {
     "duration": 0.010152,
     "end_time": "2024-01-19T04:03:15.222281",
     "exception": false,
     "start_time": "2024-01-19T04:03:15.212129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> <a id = 3>üìñRead Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77173f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae497d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:15.244829Z",
     "iopub.status.busy": "2024-01-19T04:03:15.244427Z",
     "iopub.status.idle": "2024-01-19T04:03:15.791752Z",
     "shell.execute_reply": "2024-01-19T04:03:15.790828Z"
    },
    "papermill": {
     "duration": 0.561601,
     "end_time": "2024-01-19T04:03:15.793833",
     "exception": false,
     "start_time": "2024-01-19T04:03:15.232232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"artifacts\\data_ingestion\\\\test.csv\")\n",
    "train = pd.read_csv('artifacts\\data_ingestion\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5215c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47bc19",
   "metadata": {
    "papermill": {
     "duration": 0.010271,
     "end_time": "2024-01-19T04:03:15.815493",
     "exception": false,
     "start_time": "2024-01-19T04:03:15.805222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> <a id = 4>üòÖüòÖMissing & Duplicate Values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d18c9b",
   "metadata": {
    "papermill": {
     "duration": 0.010293,
     "end_time": "2024-01-19T04:03:16.056870",
     "exception": false,
     "start_time": "2024-01-19T04:03:16.046577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id = 4.4> Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1821c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:16.080059Z",
     "iopub.status.busy": "2024-01-19T04:03:16.079636Z",
     "iopub.status.idle": "2024-01-19T04:03:16.117653Z",
     "shell.execute_reply": "2024-01-19T04:03:16.116788Z"
    },
    "papermill": {
     "duration": 0.051384,
     "end_time": "2024-01-19T04:03:16.119389",
     "exception": false,
     "start_time": "2024-01-19T04:03:16.068005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train.isnull().sum())\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6a8e08",
   "metadata": {
    "papermill": {
     "duration": 0.010215,
     "end_time": "2024-01-19T04:03:16.140429",
     "exception": false,
     "start_time": "2024-01-19T04:03:16.130214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* hmm.... Some problem will be solved at data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba0ef0",
   "metadata": {
    "papermill": {
     "duration": 0.013233,
     "end_time": "2024-01-19T04:03:16.166286",
     "exception": false,
     "start_time": "2024-01-19T04:03:16.153053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id = 4.3> Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0f5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:16.191951Z",
     "iopub.status.busy": "2024-01-19T04:03:16.191563Z",
     "iopub.status.idle": "2024-01-19T04:03:16.376479Z",
     "shell.execute_reply": "2024-01-19T04:03:16.375709Z"
    },
    "papermill": {
     "duration": 0.200022,
     "end_time": "2024-01-19T04:03:16.378008",
     "exception": false,
     "start_time": "2024-01-19T04:03:16.177986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove duplicated rows\n",
    "print(train.duplicated().sum())\n",
    "train = train.drop_duplicates()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f668c2f",
   "metadata": {
    "papermill": {
     "duration": 0.010043,
     "end_time": "2024-01-19T04:03:16.398866",
     "exception": false,
     "start_time": "2024-01-19T04:03:16.388823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> <a id = 5>EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098143ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:16.422249Z",
     "iopub.status.busy": "2024-01-19T04:03:16.421595Z",
     "iopub.status.idle": "2024-01-19T04:03:16.517178Z",
     "shell.execute_reply": "2024-01-19T04:03:16.516215Z"
    },
    "papermill": {
     "duration": 0.109975,
     "end_time": "2024-01-19T04:03:16.519037",
     "exception": false,
     "start_time": "2024-01-19T04:03:16.409062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ce47c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:16.545945Z",
     "iopub.status.busy": "2024-01-19T04:03:16.545541Z",
     "iopub.status.idle": "2024-01-19T04:03:19.943753Z",
     "shell.execute_reply": "2024-01-19T04:03:19.942858Z"
    },
    "papermill": {
     "duration": 3.413266,
     "end_time": "2024-01-19T04:03:19.946114",
     "exception": false,
     "start_time": "2024-01-19T04:03:16.532848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting every feature on the graph \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a deep copy of train and name it data\n",
    "data = train.copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['Geography'] = label_encoder.fit_transform(data['Geography'])\n",
    "data['Gender'] = label_encoder.fit_transform(data['Gender'])\n",
    "data['Surname'] = label_encoder.fit_transform(data['Surname'])\n",
    "\n",
    "data.hist(bins=50, figsize=(20,15), legend = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb002d6",
   "metadata": {
    "papermill": {
     "duration": 0.013081,
     "end_time": "2024-01-19T04:03:19.972506",
     "exception": false,
     "start_time": "2024-01-19T04:03:19.959425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "WE need to utilize the categorical columns also ... we are LabelEncoding this and many people have broken bank account , they literally have zero money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4326e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:20.000525Z",
     "iopub.status.busy": "2024-01-19T04:03:19.999991Z",
     "iopub.status.idle": "2024-01-19T04:03:20.028365Z",
     "shell.execute_reply": "2024-01-19T04:03:20.027462Z"
    },
    "papermill": {
     "duration": 0.044632,
     "end_time": "2024-01-19T04:03:20.030123",
     "exception": false,
     "start_time": "2024-01-19T04:03:19.985491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.nunique() #Uniqueness of the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9f660",
   "metadata": {
    "papermill": {
     "duration": 0.016713,
     "end_time": "2024-01-19T04:03:22.081826",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.065113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> <a id = 7>üñáüñáüì≠Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e4ed0",
   "metadata": {
    "papermill": {
     "duration": 0.016213,
     "end_time": "2024-01-19T04:03:22.114672",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.098459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id = 7.1> Creating X and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca743c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:22.148986Z",
     "iopub.status.busy": "2024-01-19T04:03:22.148590Z",
     "iopub.status.idle": "2024-01-19T04:03:22.163309Z",
     "shell.execute_reply": "2024-01-19T04:03:22.162607Z"
    },
    "papermill": {
     "duration": 0.034098,
     "end_time": "2024-01-19T04:03:22.164911",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.130813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train.drop('Exited', axis=1)\n",
    "\n",
    "y = train['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c062c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:22.201317Z",
     "iopub.status.busy": "2024-01-19T04:03:22.200472Z",
     "iopub.status.idle": "2024-01-19T04:03:22.291610Z",
     "shell.execute_reply": "2024-01-19T04:03:22.290196Z"
    },
    "papermill": {
     "duration": 0.111683,
     "end_time": "2024-01-19T04:03:22.293724",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.182041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X['Surname_encoded'] = label_encoder.fit_transform(train['Surname'])\n",
    "test['Surname_encoded'] = label_encoder.transform(test['Surname'])\n",
    "\n",
    "\n",
    "# getting list of the numerical and categorical columns\n",
    "num = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "col = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531a081",
   "metadata": {
    "papermill": {
     "duration": 0.018417,
     "end_time": "2024-01-19T04:03:22.329546",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.311129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id = 7.2> Okay I need to explain\n",
    "If you don't understand why I dropped first 'Surname' and after some processing added again, lemme explain:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791fcac",
   "metadata": {
    "papermill": {
     "duration": 0.016038,
     "end_time": "2024-01-19T04:03:22.362540",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.346502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. You can't use the Surname in the OnehotEncoder '2932' unique names , it will create '2932' features , and we will we facing the [Curse of dimensionality](https://towardsdatascience.com/curse-of-dimensionality-a-curse-to-machine-learning-c122ee33bfeb)..\n",
    "2. To avoid this we are using LabelEncoder , well what is the difference between [ONehot vs Label Encoder](https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/)??\n",
    "3. SO , we dropped 'Surname' in the dataset and then applied LabelEncoder to convert catt.. to numm. columns type , and added back \n",
    "4. Why we are doing this ??? Well, OnehotEncoder outperforms the LabelEncoder in creating useful features (so we will be using it in the main Pipeline), but when features are too much LabelEncoder is better choice , OnehoteEncoder is good to go when you have 10-20 unique values... but we have '2932'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b736d08",
   "metadata": {
    "papermill": {
     "duration": 0.017023,
     "end_time": "2024-01-19T04:03:22.396172",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.379149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id = 7.3>Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f8dbda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:22.431646Z",
     "iopub.status.busy": "2024-01-19T04:03:22.431079Z",
     "iopub.status.idle": "2024-01-19T04:03:22.437312Z",
     "shell.execute_reply": "2024-01-19T04:03:22.435851Z"
    },
    "papermill": {
     "duration": 0.026403,
     "end_time": "2024-01-19T04:03:22.439405",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.413002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data: imputation and scaling\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Preprocessing for categorical data: imputation and one-hot encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num),\n",
    "        ('cat', categorical_transformer, col)])\n",
    "\n",
    "#preprocessor is the final pipeline, we will using it before the data feds into the ml algo.... using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca749f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:22.476694Z",
     "iopub.status.busy": "2024-01-19T04:03:22.476337Z",
     "iopub.status.idle": "2024-01-19T04:03:22.532262Z",
     "shell.execute_reply": "2024-01-19T04:03:22.531271Z"
    },
    "papermill": {
     "duration": 0.07813,
     "end_time": "2024-01-19T04:03:22.534417",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.456287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f00e2",
   "metadata": {
    "papermill": {
     "duration": 0.017121,
     "end_time": "2024-01-19T04:03:22.568672",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.551551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> <a id = 8>‚öôÔ∏èFinding and Training Models With Best Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcbdda9",
   "metadata": {
    "papermill": {
     "duration": 0.016737,
     "end_time": "2024-01-19T04:03:22.602257",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.585520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What is OPtuna??\n",
    "Hmmmm.. background we need models fine tuned (meaning with best Hyperparameters) , so we are using Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee10cd",
   "metadata": {
    "papermill": {
     "duration": 0.016302,
     "end_time": "2024-01-19T04:03:22.636135",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.619833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[OPtuna](https://towardsdatascience.com/state-of-the-art-machine-learning-hyperparameter-optimization-with-optuna-a315d8564de1) is a software framework that automatically optimizes hyperparameters. It's designed for machine learning and can be used with other frameworks like TensorFlow, PyTorch, Keras, and SKlearn. \n",
    "Using OPtuna is going to help us to find best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e1a08",
   "metadata": {
    "papermill": {
     "duration": 0.0165,
     "end_time": "2024-01-19T04:03:22.669164",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.652664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id = 8.1> Random Jungle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124dce3",
   "metadata": {
    "papermill": {
     "duration": 0.01703,
     "end_time": "2024-01-19T04:03:22.702520",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.685490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[Random forests](https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/) or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the mean or average prediction of the individual trees is returned .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b018e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:22.737654Z",
     "iopub.status.busy": "2024-01-19T04:03:22.737125Z",
     "iopub.status.idle": "2024-01-19T04:03:22.742118Z",
     "shell.execute_reply": "2024-01-19T04:03:22.740941Z"
    },
    "papermill": {
     "duration": 0.024741,
     "end_time": "2024-01-19T04:03:22.743972",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.719231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't uncomment to run it this will take more time than you can think and Kaggle allows , above 12 hours\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define the hyperparameters to be optimized\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 10, 1000, step=5)\n",
    "#     max_depth = trial.suggest_int('max_depth', 5, 100)\n",
    "#     min_samples_split = trial.suggest_int('min_samples_split', 2, 50)\n",
    "#     min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 50)\n",
    "#     max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "#     bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "#     criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    \n",
    "#     # Create a Random Forest model with the specified hyperparameters\n",
    "#     model = RandomForestClassifier(\n",
    "#         n_estimators=n_estimators,\n",
    "#         max_depth=max_depth,\n",
    "#         min_samples_split=min_samples_split,\n",
    "#         min_samples_leaf=min_samples_leaf,\n",
    "#         max_features=max_features,\n",
    "#         bootstrap=bootstrap,\n",
    "#         criterion=criterion,\n",
    "#         random_state=42\n",
    "#     )\n",
    "#     pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "#     # Train the model\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "    \n",
    "#     # Make predictions on the test set\n",
    "#     predictions = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "#     # Calculate AUC-ROC as the metric to optimize\n",
    "#     auc_roc = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "#     return auc_roc\n",
    "\n",
    "# # Create a study object and optimize the objective function\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=1500)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = study.best_params\n",
    "# print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef54d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:22.779705Z",
     "iopub.status.busy": "2024-01-19T04:03:22.779163Z",
     "iopub.status.idle": "2024-01-19T04:03:22.783277Z",
     "shell.execute_reply": "2024-01-19T04:03:22.782371Z"
    },
    "papermill": {
     "duration": 0.024113,
     "end_time": "2024-01-19T04:03:22.785174",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.761061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Train the final model with the best hyperparameters on the entire dataset\n",
    "# best_model = RandomForestClassifier(**{'n_estimators': 425, 'max_depth': 13, 'min_samples_split': 41, 'min_samples_leaf': 2, \n",
    "#                                       'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy', 'random_state': 42})\n",
    "\n",
    "# Ran_best = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "    \n",
    "# Ran_best.fit(X_train, y_train)\n",
    "\n",
    "# predictions = Ran_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# auc_roc = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "# auc_roc\n",
    "\n",
    "#previous 0.8863970621948215\n",
    "# after 0.851376404143134"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c28735",
   "metadata": {
    "papermill": {
     "duration": 0.016231,
     "end_time": "2024-01-19T04:03:22.818166",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.801935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id= 8.2> My Cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c72b6e3",
   "metadata": {
    "papermill": {
     "duration": 0.016195,
     "end_time": "2024-01-19T04:03:22.850764",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.834569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[CatBoost](https://www.analyticsvidhya.com/blog/2017/08/catboost-automated-categorical-data/) is an open-source machine learning library developed by Yandex. It's an algorithm for gradient boosting on decision trees that uses decision trees for classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44afd09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:22.885334Z",
     "iopub.status.busy": "2024-01-19T04:03:22.884919Z",
     "iopub.status.idle": "2024-01-19T04:03:22.889472Z",
     "shell.execute_reply": "2024-01-19T04:03:22.888827Z"
    },
    "papermill": {
     "duration": 0.023815,
     "end_time": "2024-01-19T04:03:22.890975",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.867160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't uncomment to run it this will take more time than you can think and Kaggle allows , above 12 hours\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# def objective(trial):\n",
    "#     iterations = trial.suggest_int('iterations', 50, 1000, step=10)\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0.01, 0.5)\n",
    "#     depth = trial.suggest_int('depth', 3, 15)\n",
    "#     l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 1e-3, 1)\n",
    "\n",
    "#     model = CatBoostClassifier(\n",
    "#         iterations=iterations,\n",
    "#         learning_rate=learning_rate,\n",
    "#         depth=depth,\n",
    "#         l2_leaf_reg=l2_leaf_reg,\n",
    "#         random_state=42,\n",
    "#         verbose=0  # Set verbose to 0 to suppress CatBoost output\n",
    "#     )\n",
    "#     pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     probabilities = pipeline.predict_proba(X_test)[:, 1]  # Get the probability of the positive class\n",
    "    \n",
    "#     auc_roc = roc_auc_score(y_test, probabilities)\n",
    "    \n",
    "#     return auc_roc\n",
    "\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=1500)\n",
    "\n",
    "# best_params = study.best_params\n",
    "# print(\"Best Hyperparameters (CatBoost):\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0c465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:22.929437Z",
     "iopub.status.busy": "2024-01-19T04:03:22.928299Z",
     "iopub.status.idle": "2024-01-19T04:03:39.515976Z",
     "shell.execute_reply": "2024-01-19T04:03:39.515080Z"
    },
    "papermill": {
     "duration": 16.608793,
     "end_time": "2024-01-19T04:03:39.518133",
     "exception": false,
     "start_time": "2024-01-19T04:03:22.909340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters on the entire dataset\n",
    "best_model = CatBoostClassifier(**{'iterations': 830, 'learning_rate': 0.08238714339235984, 'depth': 5,\n",
    "                                 'l2_leaf_reg': 0.8106903985997884, 'random_state': 42, 'verbose': 0})\n",
    "\n",
    "Cat_best = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "\n",
    "Cat_best.fit(X_train, y_train)\n",
    "\n",
    "predictions = Cat_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "auc_roc\n",
    "#previous 0.8893488306520324\n",
    "# after  0.891890282220051"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081aef1e",
   "metadata": {
    "papermill": {
     "duration": 0.016357,
     "end_time": "2024-01-19T04:03:39.551426",
     "exception": false,
     "start_time": "2024-01-19T04:03:39.535069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id = 8.3 > LGBM LIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3931e0",
   "metadata": {
    "papermill": {
     "duration": 0.016386,
     "end_time": "2024-01-19T04:03:39.584656",
     "exception": false,
     "start_time": "2024-01-19T04:03:39.568270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[LightGBM](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc), short for light gradient-boosting machine, is a free and open-source distributed gradient-boosting framework for machine learning, originally developed by Microsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12308b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:39.622164Z",
     "iopub.status.busy": "2024-01-19T04:03:39.621847Z",
     "iopub.status.idle": "2024-01-19T04:03:39.626224Z",
     "shell.execute_reply": "2024-01-19T04:03:39.625472Z"
    },
    "papermill": {
     "duration": 0.025242,
     "end_time": "2024-01-19T04:03:39.628348",
     "exception": false,
     "start_time": "2024-01-19T04:03:39.603106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't uncomment to run it this will take more time than you can think and Kaggle allows , above 12 hours\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# def objective(trial):\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 1000, step=10)\n",
    "#     learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.5)\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "#     min_child_samples = trial.suggest_int('min_child_samples', 1, 20)\n",
    "#     subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "\n",
    "#     model = LGBMClassifier(\n",
    "#         n_estimators=n_estimators,\n",
    "#         learning_rate=learning_rate,\n",
    "#         max_depth=max_depth,\n",
    "#         min_child_samples=min_child_samples,\n",
    "#         subsample=subsample,\n",
    "#         colsample_bytree=colsample_bytree,\n",
    "#         random_state=42\n",
    "#     )\n",
    "#     pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     probabilities = pipeline.predict_proba(X_test)[:, 1]  # Get the probability of the positive class\n",
    "    \n",
    "#     auc_roc = roc_auc_score(y_test, probabilities)\n",
    "    \n",
    "#     return auc_roc\n",
    "\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=1500)\n",
    "\n",
    "# best_params = study.best_params\n",
    "# print(\"Best Hyperparameters (LightGBM):\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab301e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:39.664478Z",
     "iopub.status.busy": "2024-01-19T04:03:39.663872Z",
     "iopub.status.idle": "2024-01-19T04:03:56.146763Z",
     "shell.execute_reply": "2024-01-19T04:03:56.145187Z"
    },
    "papermill": {
     "duration": 16.503139,
     "end_time": "2024-01-19T04:03:56.148937",
     "exception": false,
     "start_time": "2024-01-19T04:03:39.645798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters on the entire dataset\n",
    "best_model = LGBMClassifier(**{'n_estimators': 960, 'learning_rate': 0.031725771326186744, 'max_depth': 8, 'min_child_samples': 8, \n",
    "                               'subsample': 0.7458307885861184, 'colsample_bytree': 0.5111460378911089, 'random_state': 42})\n",
    "\n",
    "LGBM_best = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "    \n",
    "LGBM_best.fit(X_train, y_train)\n",
    "\n",
    "predictions = LGBM_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "auc_roc\n",
    "#previous 0.8899706366593071\n",
    "#after 0.8932684835683227"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37562b20",
   "metadata": {
    "papermill": {
     "duration": 0.017313,
     "end_time": "2024-01-19T04:03:56.183315",
     "exception": false,
     "start_time": "2024-01-19T04:03:56.166002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id = 8.4> Extreme Guy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825b8769",
   "metadata": {
    "papermill": {
     "duration": 0.017218,
     "end_time": "2024-01-19T04:03:56.218158",
     "exception": false,
     "start_time": "2024-01-19T04:03:56.200940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[XGBoost](https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/), or eXtreme Gradient Boosting, is a machine learning algorithm that's used for supervised learning tasks like classification and regression. It's a popular algorithm because it can handle large datasets and perform well on many machine learning tasks, btw this is my boy.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238451b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:56.255603Z",
     "iopub.status.busy": "2024-01-19T04:03:56.255255Z",
     "iopub.status.idle": "2024-01-19T04:03:56.261960Z",
     "shell.execute_reply": "2024-01-19T04:03:56.260660Z"
    },
    "papermill": {
     "duration": 0.028096,
     "end_time": "2024-01-19T04:03:56.264715",
     "exception": false,
     "start_time": "2024-01-19T04:03:56.236619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't uncomment to run it this will take more time than you can think and Kaggle allows , above 12 hours\n",
    "\n",
    "# def objective(trial):\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 1000, step=10)\n",
    "#     learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.5)\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "#     min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
    "#     gamma = trial.suggest_loguniform('gamma', 1e-3, 1)\n",
    "\n",
    "#     model = XGBClassifier(\n",
    "#         n_estimators=n_estimators,\n",
    "#         learning_rate=learning_rate,\n",
    "#         max_depth=max_depth,\n",
    "#         min_child_weight=min_child_weight,\n",
    "#         gamma=gamma,\n",
    "#         random_state=42\n",
    "#     )\n",
    "#     pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     predictions = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "#     auc_roc = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "#     return auc_roc\n",
    "\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=1500)\n",
    "\n",
    "# best_params = study.best_params\n",
    "# print(\"Best Hyperparameters (XGBoost):\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c119c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:03:56.301972Z",
     "iopub.status.busy": "2024-01-19T04:03:56.301616Z",
     "iopub.status.idle": "2024-01-19T04:04:09.750820Z",
     "shell.execute_reply": "2024-01-19T04:04:09.749748Z"
    },
    "papermill": {
     "duration": 13.47002,
     "end_time": "2024-01-19T04:04:09.752954",
     "exception": false,
     "start_time": "2024-01-19T04:03:56.282934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters on the entire dataset\n",
    "best_model = XGBClassifier(**{'n_estimators': 810, 'learning_rate': 0.07921079869615913, 'max_depth': 5,\n",
    "                            'min_child_weight': 8, 'gamma': 0.27423983829634263, 'random_state': 42, 'objective': 'binary:logistic',\n",
    "                            'eval_metric': 'auc', 'n_jobs': -1})\n",
    "\n",
    "XGB_best = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "    \n",
    "XGB_best.fit(X_train, y_train)\n",
    "\n",
    "predictions = XGB_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "auc_roc\n",
    "#previous 0.8895683275081493\n",
    "#after 0.8930475156029525"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e8afa",
   "metadata": {
    "papermill": {
     "duration": 0.016645,
     "end_time": "2024-01-19T04:04:09.787080",
     "exception": false,
     "start_time": "2024-01-19T04:04:09.770435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> <a id = 9>üëÄüëÅFInal MOdel WIth VOting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12f0fe",
   "metadata": {
    "papermill": {
     "duration": 0.016721,
     "end_time": "2024-01-19T04:04:09.820717",
     "exception": false,
     "start_time": "2024-01-19T04:04:09.803996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A [Voting Classifier](https://medium.com/@imamitsingh/voting-classifiers-in-machine-learning-a532935fe592#:~:text=A%20Voting%20Classifier%20is%20a,chosen%20class%20as%20the%20output.) is a machine learning model that trains on an ensemble of numerous models and predicts an output (class) based on their highest probability of chosen class as the output.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d15d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:04:09.856907Z",
     "iopub.status.busy": "2024-01-19T04:04:09.856238Z",
     "iopub.status.idle": "2024-01-19T04:04:58.089732Z",
     "shell.execute_reply": "2024-01-19T04:04:58.088159Z"
    },
    "papermill": {
     "duration": 48.270213,
     "end_time": "2024-01-19T04:04:58.107922",
     "exception": false,
     "start_time": "2024-01-19T04:04:09.837709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Create a VotingClassifier with the three XGBoost models\n",
    "voting = VotingClassifier(estimators=[\n",
    "    ('Model1', LGBM_best),\n",
    "    ('Model2', XGB_best),\n",
    "    ('Model3', Cat_best)\n",
    "], voting='soft', weights = [0.5, 0.3, 0.2])\n",
    "\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "predictions = voting.predict_proba(X_test)[:, 1]\n",
    "predict = voting.predict(X_test)\n",
    "\n",
    "auc_roc = roc_auc_score(y_test, predictions)\n",
    "acuu = accuracy_score(y_test, predict) \n",
    "auc_roc, acuu\n",
    "\n",
    "# with all 4 0.8898841550500115\n",
    "#with best three 0.8901529119994704\n",
    "# with best two 0.890129825391591\n",
    "# with Cat & XGB 0.8898752572908788\n",
    "# with LGBM & Cat 0.8900580892007095\n",
    "# Stack two 0.8901571929273973\n",
    "# Stack three 0.8901870809637238\n",
    "# 0.8936971525454481, 0.8702259548090382"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794eadf",
   "metadata": {
    "papermill": {
     "duration": 0.016288,
     "end_time": "2024-01-19T04:04:58.140718",
     "exception": false,
     "start_time": "2024-01-19T04:04:58.124430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> <a id = 10>üìäGenerate Predictions and Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bcc1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T04:04:58.178924Z",
     "iopub.status.busy": "2024-01-19T04:04:58.178563Z",
     "iopub.status.idle": "2024-01-19T04:05:56.388507Z",
     "shell.execute_reply": "2024-01-19T04:05:56.387540Z"
    },
    "papermill": {
     "duration": 58.247278,
     "end_time": "2024-01-19T04:05:56.406839",
     "exception": false,
     "start_time": "2024-01-19T04:04:58.159561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "voting.fit(X, y)\n",
    "\n",
    "# Making predictions on the test set\n",
    "pred = voting.predict_proba(test)[:, 1]\n",
    "\n",
    "pred.to_csv('sample_submission.csv', index = False)\n",
    "\n",
    "pred.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7405009,
     "sourceId": 65711,
     "sourceType": "competition"
    },
    {
     "datasetId": 3191230,
     "sourceId": 5536933,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 170.054295,
   "end_time": "2024-01-19T04:05:57.346706",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-19T04:03:07.292411",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
